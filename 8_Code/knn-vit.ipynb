{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-05-24T14:17:05.215793Z","iopub.status.busy":"2024-05-24T14:17:05.214940Z","iopub.status.idle":"2024-05-24T14:17:05.219994Z","shell.execute_reply":"2024-05-24T14:17:05.218924Z","shell.execute_reply.started":"2024-05-24T14:17:05.215753Z"},"trusted":true},"outputs":[],"source":["!pip install datasets\n","!pip install accelerate -U"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T14:54:49.437045Z","iopub.status.busy":"2024-05-24T14:54:49.436591Z","iopub.status.idle":"2024-05-24T14:55:43.674709Z","shell.execute_reply":"2024-05-24T14:55:43.673544Z","shell.execute_reply.started":"2024-05-24T14:54:49.437008Z"},"trusted":true},"outputs":[],"source":["import timm\n","from PIL import Image\n","from datasets import load_dataset\n","import numpy as np\n","from sklearn.preprocessing import LabelEncoder\n","from torch.utils.data import Dataset\n","import torch\n","import matplotlib.pyplot as plt\n","from sklearn.metrics import accuracy_score, confusion_matrix, classification_report, f1_score, roc_curve, auc, roc_auc_score\n","import seaborn as sns\n","\n","# Load the dataset\n","dataset = load_dataset('GaryHuang/NTU_geolocation')\n","full_dataset = dataset['train']\n","\n","# Verify the dataset size\n","print(f\"Full dataset size: {len(full_dataset)}\")\n","\n","# Convert string labels to numeric labels\n","label_encoder = LabelEncoder()\n","numerical_labels = label_encoder.fit_transform(full_dataset['label'])  # Replace 'label' with the actual label column name if different\n","\n","# Replace the original labels with numeric labels\n","full_dataset = full_dataset.remove_columns('label')\n","full_dataset = full_dataset.add_column('label', numerical_labels)\n","\n","# Define the sample size (e.g., 10% of the full dataset)\n","sample_size = int(len(full_dataset))  # Adjust this percentage based on your needs\n","\n","# Shuffle the dataset and sample a subset\n","np.random.seed(42)  # For reproducibility\n","sample_indices = np.random.permutation(len(full_dataset))[:sample_size]\n","sampled_dataset = full_dataset.select(sample_indices)\n","\n","# Verify the sampled dataset size\n","print(f\"Sampled dataset size: {len(sampled_dataset)}\")\n","\n","# Define the sizes for train and test split: 80%, 20%\n","train_size = int(0.85 * len(sampled_dataset))\n","test_size = len(sampled_dataset) - train_size  # Ensure all samples are used\n","\n","# Generate shuffled indices for the sampled dataset\n","indices = np.random.permutation(len(sampled_dataset))\n","\n","# Verify indices are within bounds\n","print(f\"Max index in sampled dataset: {indices.max()}\")\n","print(f\"Sampled dataset length: {len(sampled_dataset)}\")\n","\n","# Split indices for each dataset\n","train_indices = indices[:train_size]\n","test_indices = indices[train_size:]\n","\n","# Create subsets using the indices\n","train_subset = sampled_dataset.select(train_indices)\n","test_subset = sampled_dataset.select(test_indices)\n","\n","# Print the sizes to confirm\n","print(f\"Train subset size: {len(train_subset)}\")\n","print(f\"Test subset size: {len(test_subset)}\")\n","\n","# Load the pre-trained model\n","device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n","model = timm.create_model('vit_large_patch16_224.augreg_in21k_ft_in1k', pretrained=True, num_classes=0)\n","model = model.eval().to(device)\n","\n","# Get model specific transforms (normalization, resize)\n","data_config = timm.data.resolve_model_data_config(model)\n","train_transform = timm.data.create_transform(**data_config, is_training=True)\n","transform = timm.data.create_transform(**data_config, is_training=False)\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, dataset, transform=None):\n","        self.dataset = dataset\n","        self.transform = transform\n","\n","    def __len__(self):\n","        return len(self.dataset)\n","\n","    def __getitem__(self, idx):\n","        if idx >= len(self.dataset):\n","            raise IndexError(f\"Index {idx} is out of bounds for dataset with size {len(self.dataset)}\")\n","        item = self.dataset[idx]\n","        image = Image.fromarray(np.array(item['image']))\n","        label = item['label']\n","        \n","        if self.transform:\n","            image = self.transform(image)\n","        \n","        return image, label\n","    \n","    def get_embeddings(self, model, device):\n","        embeddings = []\n","        labels = []\n","        with torch.no_grad():\n","            for idx in range(len(self.dataset)):\n","                if idx >= len(self.dataset):\n","                    print(f\"Index {idx} is out of bounds for dataset with size {len(self.dataset)}\")\n","                    continue\n","                item = self.dataset[idx]\n","                image = Image.fromarray(np.array(item['image']))\n","                label = item['label']\n","                image = self.transform(image).unsqueeze(0).to(device)\n","                embedding = model.forward_features(image)\n","                embedding = model.forward_head(embedding, pre_logits=True)\n","                embeddings.append(embedding.cpu().numpy().flatten())\n","                labels.append(label)\n","        return np.array(embeddings), np.array(labels)\n","\n","# Create datasets\n","train_dataset = CustomDataset(train_subset, transform=train_transform)\n","test_dataset = CustomDataset(test_subset, transform=transform)\n","\n","# Debug print statement to verify dataset lengths\n","print(f\"Train dataset length: {len(train_dataset)}\")\n","print(f\"Test dataset length: {len(test_dataset)}\")\n","\n","# Extract embeddings\n","print(\"Extracting train embeddings...\")\n","train_embeddings, train_labels = train_dataset.get_embeddings(model, device)\n","print(\"Extracting test embeddings...\")\n","test_embeddings, test_labels = test_dataset.get_embeddings(model, device)\n","\n","# Debug print statement to verify embeddings\n","print(f\"Train embeddings shape: {train_embeddings.shape}\")\n","print(f\"Test embeddings shape: {test_embeddings.shape}\")\n","\n","# Verify embeddings and labels length\n","print(f\"Train embeddings length: {len(train_embeddings)}, Train labels length: {len(train_labels)}\")\n","print(f\"Test embeddings length: {len(test_embeddings)}, Test labels length: {len(test_labels)}\")\n","\n","# KNN from scratch\n","class KNNClassifier:\n","    def __init__(self, k=3):\n","        self.k = k\n","    \n","    def fit(self, X_train, y_train):\n","        self.X_train = X_train\n","        self.y_train = y_train\n","    \n","    def predict(self, X_test):\n","        predictions = []\n","        for x in X_test:\n","            distances = np.linalg.norm(self.X_train - x, axis=1)\n","            k_indices = np.argsort(distances)[:self.k]\n","            k_nearest_labels = self.y_train[k_indices]\n","            most_common = np.bincount(k_nearest_labels).argmax()\n","            predictions.append(most_common)\n","        return np.array(predictions)\n","    \n","    def predict_proba(self, X_test):\n","        probs = []\n","        for x in X_test:\n","            distances = np.linalg.norm(self.X_train - x, axis=1)\n","            k_indices = np.argsort(distances)[:self.k]\n","            k_nearest_labels = self.y_train[k_indices]\n","            proba = np.bincount(k_nearest_labels, minlength=len(np.unique(self.y_train))) / self.k\n","            probs.append(proba)\n","        return np.array(probs)\n","\n","# Using the custom KNN\n","knn = KNNClassifier(k=3)\n","knn.fit(train_embeddings, train_labels)\n","\n","# Evaluate on test set\n","test_preds = knn.predict(test_embeddings)\n","test_probs = knn.predict_proba(test_embeddings)\n","test_accuracy = accuracy_score(test_labels, test_preds)\n","print(f\"Test Accuracy: {test_accuracy:.4f}\")\n","print(\"Test Classification Report:\")\n","print(classification_report(test_labels, test_preds))\n","\n","# Save the results\n","# Confusion matrix\n","cm = confusion_matrix(test_labels, test_preds)\n","plt.figure(figsize=(10, 7))\n","sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n","plt.title('Confusion Matrix')\n","plt.xlabel('Predicted')\n","plt.ylabel('True')\n","plt.savefig('confusion_matrix.png')\n","plt.close()\n","\n","# Calculate evaluation metrics\n","f1 = f1_score(test_labels, test_preds, average='weighted')\n","roc_auc_macro = roc_auc_score(test_labels, test_probs, multi_class='ovr', average='macro')\n","roc_auc_weighted = roc_auc_score(test_labels, test_probs, multi_class='ovr', average='weighted')\n","\n","# Plot and save ROC curve\n","n_classes = len(label_encoder.classes_)\n","fpr = {}\n","tpr = {}\n","roc_auc = {}\n","\n","for i in range(n_classes):\n","    fpr[i], tpr[i], _ = roc_curve(test_labels == i, test_probs[:, i])\n","    roc_auc[i] = auc(fpr[i], tpr[i])\n","\n","plt.figure()\n","for i in range(n_classes):\n","    plt.plot(fpr[i], tpr[i], label=f'Class {i} (AUC = {roc_auc[i]:.2f})')\n","\n","plt.plot([0, 1], [0, 1], 'k--')\n","plt.xlim([0.0, 1.0])\n","plt.ylim([0.0, 1.05])\n","plt.xlabel('False Positive Rate')\n","plt.ylabel('True Positive Rate')\n","plt.title('Receiver Operating Characteristic')\n","plt.legend(loc='lower right')\n","plt.savefig('roc_curve.png')\n","plt.close()\n","\n","# Write report to text file\n","with open('evaluation_report.txt', 'w') as f:\n","    f.write(f\"Evaluation Accuracy: {test_accuracy:.4f}\\n\")\n","    f.write(f\"F1 Score: {f1:.4f}\\n\")\n","    f.write(f\"Macro AUC: {roc_auc_macro:.4f}\\n\")\n","    f.write(f\"Weighted AUC: {roc_auc_weighted:.4f}\\n\")\n","    f.write(\"\\nClass-wise AUC Scores:\\n\")\n","    for i in range(n_classes):\n","        f.write(f\"Class {i} AUC: {roc_auc[i]:.4f}\\n\")\n","\n","print(\"Evaluation report saved to evaluation_report.txt\")\n","print(\"Confusion matrix image saved to confusion_matrix.png\")\n","print(\"ROC curve image saved to roc_curve.png\")"]}],"metadata":{"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
